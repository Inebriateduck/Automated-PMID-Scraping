{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww30040\viewh16620\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # If this is your first time running this script, uncomment the 3 install commands below:\
# install.packages("R.utils") \
# install.packages("easyPubMed")\
# install.packages("readr")\
\
library(R.utils)      # Contains timeout handling function\
library(easyPubMed)   # Accesses Pubmed data\
library(readr)        # Reads + writes CSV files\
\
# Define input and output directories\
input_path <- \'91[input path here]\'92 # Directory containing input CSV files\
output_path <- \'91[output path here\'92]  # Directory to save output files\
\
if (!dir.exists(output_path)) \{\
  dir.create(output_path)\
\}\
\
# Get list of input CSV files from the input directory\
input_files <- list.files(input_path, pattern = "\\\\.csv$", full.names = TRUE)\
\
# PMID timeout processing to prevent hang-crash issues with faulty PMIDs\
process_pmid <- function(pmid) \{\
  myquery <- paste(pmid, '[PMID]', sep = "")  \
  pubmedID <- tryCatch(\{\
    withTimeout(\{\
      get_pubmed_ids(myquery)  # Fetch PubMed ID\
    \}, timeout = 25, onTimeout = "error")  # Timeout set to 25 seconds, replace the 25 with your maximum acceptable hang time\
  \}, error = function(e) \{\
    print(paste("Timeout or error for PMID:", pmid))  # Print error message\
    return(NULL)  # Return NULL if an error occurs\
  \})\
 \
  if (is.null(pubmedID)) \{\
    return(NULL)  # Skip if fetching PubMed ID fails, this is a redundant layer of security on top of the timeout function\
  \}\
  \
  abstractXML <- fetch_pubmed_data(pubmedID)  # Fetches PubMed data\
  if (is.null(abstractXML) || length(abstractXML) == 0) \{\
    return(NULL)  # Skip if no data is fetched, another redundant layer of protection against hang-crash issues\
  \}\
  \
  abstractlist <- articles_to_list(abstractXML)  # Convert XML data to a list of articles\
  if (length(abstractlist) == 0) \{\
    return(NULL)  # Skip if no articles are found, yet another layer of security\
  \}\
  \
  # Convert the first article to a DataFrame\
  dftemp <- article_to_df(pubmedArticle = abstractlist[[1]], autofill = TRUE, max_chars = 10)\
  return(dftemp)\
\}\
\
# Process each input file\
for (input_file in input_files) \{\
  file_base_name <- tools::file_path_sans_ext(basename(input_file))  # Get the base name of the file\
  df <- read_csv(input_file, col_names = FALSE)  # Read the input CSV file without headers\
  \
  print(paste("Processing file:", input_file))\
\
  # Initialize the output DataFrame\
  dfoutput <- data.frame(\
    pmid = character(), doi = character(), title = character(),\
    abstract = character(), year = character(), month = character(),\
    day = character(), jabbrv = character(), journal = character(),\
    keywords = character(), lastname = character(), firstname = character(),\
    affiliation = character(), email = character(),\
    stringsAsFactors = FALSE\
  )\
\
  # Process each PMID in the file\
  for (i in 1:nrow(df)) \{\
    pmid <- df[[i, 1]]  # Extract the PMID\
    print(paste("Processing PMID:", pmid))\
    \
    # Process the PMID and append to the output DataFrame if valid\
    dftemp <- process_pmid(pmid)\
    if (!is.null(dftemp)) \{\
      missing_cols <- setdiff(names(dfoutput), names(dftemp))  # Find missing columns\
      dftemp[missing_cols] <- NA  # Add missing columns with NA values\
      dftemp <- dftemp[, names(dfoutput)]  # Align column order\
      dfoutput <- rbind(dfoutput, dftemp)  # Append to the output DataFrame\
    \}\
  \}\
  #The following function allows naming in the format of \'93PMID_output_PRAttitudesofAIC_XXXX-XXXX_MMMDDYYXY.csv\'94 where XY = initials when using the initial naming format \'93PMIDs_PRAttitudesofAIC_XXXX-XXXX_MMMDDYYXY.csv\'94.\
  #change components here at your own discretion to allow automated renaming of files\
\
  # Remove "PMIDs_" and date/initials suffix from the base file name\
  base_name <- sub("^PMIDs_", "", file_base_name)\
  base_name <- sub("_Nov.*", "", base_name)\
\
  # Generate the new output file name\
  current_date <- format(Sys.Date(), "%b%d%y")  # Get current date in MMMDDYY format\
  first_initial <- \'93X\'94  # Replace with your first initial\
  last_initial <- \'93Y\'94   # Replace with your last initial\
  output_file <- file.path(output_path, paste0(\
    "PMID_Output_", base_name, "_", current_date, first_initial, last_initial, ".csv"\
  ))\
\
  # Save the output DataFrame to a CSV file\
  write_csv(dfoutput, output_file)\
  print(paste("Saved output to:", output_file))\
\}\
\
# Daniel Fry 2024, base code provided by Dr. Jeremy Ng.\
\
\
}